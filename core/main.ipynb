{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-14T20:08:55.154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlink\n",
    "from imageai.Detection import VideoObjectDetection, ObjectDetection\n",
    "\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def crop_frame(frame, target_img_name, y1=150, y2=500, x1=0, x2=1000):\n",
    "    \"\"\"\n",
    "    only crop frame to evaluate the baseline. not a offical function, therefore outsied the class. will be deleted after evaluation.\n",
    "    \"\"\"\n",
    "    frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "    if not os.path.isdir('.\\\\baseline_dublin_night'):\n",
    "        os.makedirs('.\\\\baseline_dublin_night')\n",
    "    path = '.\\\\baseline_dublin_night'\n",
    "    cv2.imwrite(os.path.join(path, target_img_name), frame)\n",
    "    return frame\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "#list of webcam\n",
    "london = 'https://www.earthcam.com/world/england/london/abbeyroad/?cam=abbeyroad_uk'\n",
    "timesquare = 'https://www.earthcam.com/usa/newyork/timessquare/?cam=tsrobo1'\n",
    "dublin = 'https://www.earthcam.com/world/ireland/dublin/?cam=templebar'\n",
    "######################################################################################################\n",
    "#list of timezone\n",
    "Dublin = 'Europe/Dublin'\n",
    "London = 'Europe/London'\n",
    "NYC = 'America/New_York'\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "\n",
    "class CountingObject(object):\n",
    "    \"\"\"\n",
    "    A class of counting objects\n",
    "    \"\"\"\n",
    "\n",
    "    algos = {\n",
    "        \"resnet\": \"resnet50_coco_best_v2.0.1.h5\",\n",
    "        \"yolov3\": \"yolo.h5\",\n",
    "        \"yolo_tiny\": \"yolo-tiny.h5\"\n",
    "    }\n",
    "\n",
    "    def __init__(self, stream_link):\n",
    "        self.stream_link = stream_link\n",
    "        self.streams = streamlink.streams(stream_link)\n",
    "        if self.streams is None:\n",
    "            raise ValueError(\"cannot open the stream link %s\" % stream_link)\n",
    "\n",
    "        #change 1, self detect quality\n",
    "        q = list(self.streams.keys())[0]\n",
    "        self.stream = self.streams['%s' % q]\n",
    "\n",
    "        self.target_img_path = os.getcwd()\n",
    "\n",
    "        self.detector = ObjectDetection()\n",
    "        if self.detector is None:\n",
    "            raise ValueError(\"Detector of objects is None\")\n",
    "\n",
    "    def detector_init(self, algo=\"resnet\", speed=\"nomal\"):\n",
    "        \"\"\"\n",
    "        Must be invoked after instantiate for initialize a object detector. \n",
    "        \n",
    "        Args:\n",
    "            algo (str): The algorithm of object detection tasks. \"resnet\"(default), \"yolov3\", \"yolo_tiny\".\n",
    "            speed (str): The detection speed for object detetion tasks. \"normal\"(default), \"fast\", \"faster\" , \"fastest\" and \"flash\".\n",
    "        \n",
    "        Returns:\n",
    "            void\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        if algo == \"resnet\":\n",
    "            self.detector.setModelTypeAsRetinaNet()\n",
    "            self.detector.setModelPath(\n",
    "                os.path.join(self.target_img_path, self.algos[\"resnet\"]))\n",
    "        elif algo == \"yolov3\":\n",
    "            self.detector.setModelTypeAsYOLOv3()\n",
    "            self.detector.setModelPath(\n",
    "                os.path.join(self.target_img_path, self.algos[\"yolov3\"]))\n",
    "        elif algo == \"yolo_tiny\":\n",
    "            self.detector.setModelTypeAsTinyYOLOv3()\n",
    "            self.detector.setModelPath(\n",
    "                os.path.join(self.target_img_path, self.algos[\"yolo_tiny\"]))\n",
    "        else:\n",
    "            print(\"Given algorithm of object detection is invalid.\")\n",
    "            return\n",
    "\n",
    "        self.detector.loadModel(detection_speed=speed)\n",
    "        self.custom_objects = self.detector.CustomObjects(person=True)\n",
    "\n",
    "    def put_text_to_img(self,\n",
    "                        img,\n",
    "                        text,\n",
    "                        pos=(50, 50),\n",
    "                        fontColor=(0, 0, 255),\n",
    "                        lineType=2):\n",
    "        if img is None:\n",
    "            print(\"Put text to a none image.\")\n",
    "            return\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 1\n",
    "\n",
    "        cv2.putText(img, text, pos, font, fontScale, fontColor, lineType)\n",
    "\n",
    "    def capture_frame_by_stream_wrapper(self,\n",
    "                                        image_prefix=\"stream\",\n",
    "                                        mprob=30,\n",
    "                                        num_im=6,\n",
    "                                        time_interval=10,\n",
    "                                        tz=None):\n",
    "        print(\n",
    "            \"The current conuting function is based on capture frame by stream.\"\n",
    "        )\n",
    "\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        frames_res = []\n",
    "        if num_im <= 0:\n",
    "            try:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    i = i + 1\n",
    "                    frame_res = self.capture_frame_by_stream(\n",
    "                        image_prefix, i, mprob, tz)\n",
    "                    frames.res.append(frame_res)\n",
    "                    time.sleep(time_interval)\n",
    "            except KeyboardInterrupt:\n",
    "                return frames_res\n",
    "                print('Abort by key interrupt.')\n",
    "        else:\n",
    "            for i in range(num_im):\n",
    "                frame_res = self.capture_frame_by_stream(\n",
    "                    image_prefix, i, mprob, tz)\n",
    "                frames_res.append(frame_res)\n",
    "                time.sleep(time_interval)\n",
    "\n",
    "            return frames_res\n",
    "\n",
    "    def capture_frame_by_stream(self,\n",
    "                                image_prefix=\"stream\",\n",
    "                                image_index=0,\n",
    "                                mprob=30,\n",
    "                                tz=None) -> int:\n",
    "        video_cap = cv2.VideoCapture(self.stream.url)\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "\n",
    "        if video_cap is None:\n",
    "            print(\"Open webcam [%s] failed.\" % self.stream.url)\n",
    "            return None\n",
    "        else:\n",
    "            ret, frame = video_cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Captured frame is broken.\")\n",
    "                video_cap.release()\n",
    "                return None\n",
    "            else:\n",
    "                print(\"-----------------------------------------------------\")\n",
    "\n",
    "                if tz is None:\n",
    "                    current_time = datetime.utcnow().strftime(\n",
    "                        \"%a %Y-%m-%d %H:%M:%S\")\n",
    "                    print('### time zone is None, therefore use utc time###')\n",
    "                else:\n",
    "                    current_time = datetime.now(\n",
    "                        timezone(tz)).strftime(\"%a %Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                print(\"Capturing frame %d.\" % image_index)\n",
    "                target_img_name = \"{}{}.png\".format(image_prefix, image_index)\n",
    "                frame = crop_frame(\n",
    "                    frame,\n",
    "                    target_img_name)  # comment to unuse the crop function.\n",
    "\n",
    "                detections = self.detector.detectCustomObjectsFromImage(\n",
    "                    custom_objects=self.custom_objects,\n",
    "                    input_type=\"array\",\n",
    "                    input_image=frame,\n",
    "                    output_image_path=os.path.join(dir_path, target_img_name),\n",
    "                    minimum_percentage_probability=mprob)\n",
    "\n",
    "                print(\n",
    "                    \"The number of person in frame %d (%s):\" %\n",
    "                    (image_index, target_img_name), len(detections))\n",
    "                print(\n",
    "                    \"The current time in frame %d (%s):\" %\n",
    "                    (image_index, target_img_name), current_time)\n",
    "\n",
    "                img = cv2.imread(os.path.join(dir_path, target_img_name))\n",
    "                # put the number of persons to the image and put timestamp to the image\n",
    "                self.put_text_to_img(\n",
    "                    img, \"The number of person:%s \" % str(len(detections)))\n",
    "                self.put_text_to_img(\n",
    "                    img, \"The current time:%s \" % current_time, pos=(50, 300))\n",
    "\n",
    "                cv2.imwrite(os.path.join(dir_path, target_img_name), img)\n",
    "                video_cap.release()\n",
    "\n",
    "                return target_img_name, len(detections), current_time\n",
    "#                 return {'img_name':target_img_name, 'detected_num':len(detections),'time':current_time}\n",
    "\n",
    "    def capture_frame_by_screenshot_wrapper(self,\n",
    "                                            image_prefix=\"screenshot\",\n",
    "                                            mprob=30,\n",
    "                                            num_im=6,\n",
    "                                            time_interval=10,\n",
    "                                            tz=None):\n",
    "        print(\n",
    "            \"The current conuting function is based on capture frame by screenshot.\"\n",
    "        )\n",
    "\n",
    "        frames_res = []\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        if num_im <= 0:\n",
    "            try:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    i = i + 1\n",
    "                    frame_res = self.capture_frame_by_screenshot(\n",
    "                        image_prefix, i, mprob, tz)\n",
    "                    frames_res.append(frame_res)\n",
    "                    time.sleep(time_interval)\n",
    "            except KeyboardInterrupt:\n",
    "                if self.driver is not None:\n",
    "                    self.driver.quit()\n",
    "                return frames_res\n",
    "                print('Abort by key interrupt.')\n",
    "        else:\n",
    "            for i in range(num_im):\n",
    "                frame_res = self.capture_frame_by_screenshot(\n",
    "                    image_prefix, i, mprob, tz)\n",
    "                frames_res.append(frame_res)\n",
    "                time.sleep(time_interval)\n",
    "\n",
    "            if self.driver is not None:\n",
    "                self.driver.quit()\n",
    "\n",
    "            return frames_res\n",
    "\n",
    "    def capture_frame_by_screenshot(self,\n",
    "                                    image_prefix=\"screenshot\",\n",
    "                                    image_index=0,\n",
    "                                    mprob=30,\n",
    "                                    num_im=6,\n",
    "                                    tz=None) -> int:\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "\n",
    "        if self.driver is None:\n",
    "            print(\"Web driver is none.\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"-----------------------------------------------------\")\n",
    "\n",
    "            if tz is None:\n",
    "                current_time = datetime.utcnow().strftime(\n",
    "                    \"%a %Y-%m-%d %H:%M:%S\")\n",
    "                print('### time zone is None, therefore use utc time###')\n",
    "            else:\n",
    "                current_time = datetime.now(\n",
    "                    timezone(tz)).strftime(\"%a %Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            target_img_name = \"{}{}.png\".format(image_prefix, image_index)\n",
    "            print(\"Taking screenshot %d...\" % image_index)\n",
    "            self.driver.save_screenshot(\n",
    "                os.path.join(dir_path, target_img_name))\n",
    "            detections = self.detector.detectCustomObjectsFromImage(\n",
    "                custom_objects=self.custom_objects,\n",
    "                input_image=os.path.join(dir_path,\n",
    "                                         target_img_name),\n",
    "                output_image_path=os.path.join(dir_path, target_img_name),\n",
    "                minimum_percentage_probability=mprob)\n",
    "\n",
    "            print(\n",
    "                \"The number of person in frame %d (%s):\" % (image_index,\n",
    "                                                            target_img_name),\n",
    "                len(detections))\n",
    "            print(\n",
    "                \"The current time in frame %d (%s):\" %\n",
    "                (image_index, target_img_name), current_time)\n",
    "\n",
    "            img = cv2.imread(os.path.join(dir_path, target_img_name))\n",
    "            # put the number of persons to the image\n",
    "            self.put_text_to_img(\n",
    "                img, \"The number of person is:%s\" % str(len(detections)))\n",
    "            self.put_text_to_img(\n",
    "                img, \"The current time:%s \" % current_time, pos=(50, 300))\n",
    "\n",
    "            cv2.imwrite(os.path.join(dir_path, target_img_name), img)\n",
    "\n",
    "            return target_img_name, len(detections), current_time\n",
    "\n",
    "    def init_webdriver(self):\n",
    "        self.driver = webdriver.Chrome(\n",
    "        )  # Optional argument, if not specified will search path.\n",
    "        self.driver.get(self.stream_link)\n",
    "        time.sleep(15)  # Jump over the ads\n",
    "\n",
    "\n",
    "#     def store_baseline_info_in_csv(self, info):\n",
    "#         if info is None:\n",
    "#             print(\"Given baseline data is None.\")\n",
    "#             return\n",
    "#         baseline_info_path = os.path.join(self.target_img_path, \"baseline_tmp.csv\")\n",
    "\n",
    "#         with open(baseline_info_path, \"w+\") as csv_file:\n",
    "#             field_names = [\"img_name\", \"detected_num\",\"time\", \"countable_num\"]\n",
    "#             csv_writer = csv.DictWriter(csv_file, fieldnames= field_names, restval=0)\n",
    "#             csv_writer.writeheader()\n",
    "#             for item in info:\n",
    "#                 csv_writer.writerow(item)\n",
    "\n",
    "    def stroe_info_in_df_csv(self, image_prefix=\"counting_person\"):\n",
    "        df = pd.DataFrame(\n",
    "            np.array(res), columns=['image_name', 'detected_num', 'time'])\n",
    "        df[\"counted_num\"] = \"\"  #only for baseline\n",
    "        df.to_csv(\n",
    "            path_or_buf=os.path.join(self.target_img_path, \"%s.csv\" %\n",
    "                                     image_prefix))\n",
    "        return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #     scheduler = BlockingScheduler()\n",
    "    print(\"Starting...\")\n",
    "    counting_person = CountingObject(dublin)\n",
    "    counting_person.detector_init()\n",
    "\n",
    "    by_stream_flag = True\n",
    "    img_prefix = \"Dublin_night\"\n",
    "    res = []\n",
    "    if by_stream_flag:\n",
    "        res = counting_person.capture_frame_by_stream_wrapper(\n",
    "            image_prefix=img_prefix, num_im=100, time_interval=180, tz=Dublin)\n",
    "\n",
    "    else:\n",
    "        counting_person.init_webdriver()\n",
    "        res = counting_person.capture_frame_by_screenshot_wrapper(num_im=2)\n",
    "\n",
    "#     counting_person.store_baseline_info_in_csv(res)\n",
    "    df = counting_person.stroe_info_in_df_csv(image_prefix=img_prefix)\n",
    "    display(df)\n",
    "\n",
    "    print('###Exit...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
