{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T23:50:18.936655Z",
     "start_time": "2018-12-27T21:14:38.372458Z"
    },
    "code_folding": [
     324
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "The current conuting function is based on capture frame by screenshot.\n",
      "-----------------------------------------------------\n",
      "### time zone is None, therefore use utc time###\n",
      "Taking screenshot 0...\n",
      "The number of person in frame 0 (screenshot0.png): 10\n",
      "The current time in frame 0 (screenshot0.png): Mon 2019-01-07 19:58:09\n",
      "-----------------------------------------------------\n",
      "### time zone is None, therefore use utc time###\n",
      "Taking screenshot 1...\n",
      "The number of person in frame 1 (screenshot1.png): 11\n",
      "The current time in frame 1 (screenshot1.png): Mon 2019-01-07 19:58:25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>detected_num</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>screenshot0.png</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon 2019-01-07 19:58:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>screenshot1.png</td>\n",
       "      <td>11</td>\n",
       "      <td>Mon 2019-01-07 19:58:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name detected_num                     time\n",
       "0  screenshot0.png           10  Mon 2019-01-07 19:58:09\n",
       "1  screenshot1.png           11  Mon 2019-01-07 19:58:25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Exit...\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlink\n",
    "from imageai.Detection import ObjectDetection\n",
    "\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "#list of webcam\n",
    "london = 'https://www.earthcam.com/world/england/london/abbeyroad/?cam=abbeyroad_uk'\n",
    "timesquare = 'https://www.earthcam.com/usa/newyork/timessquare/?cam=tsrobo1'\n",
    "dublin = 'https://www.earthcam.com/world/ireland/dublin/?cam=templebar'\n",
    "######################################################################################################\n",
    "#list of timezone\n",
    "Dublin = 'Europe/Dublin'\n",
    "London = 'Europe/London'\n",
    "NYC = 'America/New_York'\n",
    "######################################################################################################\n",
    "\n",
    "\n",
    "class CountingObject(object):\n",
    "    \"\"\"\n",
    "    A class of counting objects\n",
    "    \"\"\"\n",
    "\n",
    "    algos = {\n",
    "        \"resnet\": \"resnet50_coco_best_v2.0.1.h5\",\n",
    "        \"yolov3\": \"yolo.h5\",\n",
    "        \"yolo_tiny\": \"yolo-tiny.h5\"\n",
    "    }\n",
    "\n",
    "    def __init__(self, stream_link):\n",
    "        self.stream_link = stream_link\n",
    "        self.streams = streamlink.streams(stream_link)\n",
    "        if self.streams is None:\n",
    "            raise ValueError(\"cannot open the stream link %s\" % stream_link)\n",
    "\n",
    "        q = list(self.streams.keys())[0]\n",
    "        self.stream = self.streams['%s' % q]\n",
    "\n",
    "        self.target_img_path = os.getcwd()\n",
    "\n",
    "        self.detector = ObjectDetection()\n",
    "        if self.detector is None:\n",
    "            raise ValueError(\"Detector of objects is None\")\n",
    "\n",
    "    def detector_init(self, algo=\"resnet\", speed=\"nomal\"):\n",
    "        \"\"\"\n",
    "        Must be invoked after instantiate for initialize a object detector. \n",
    "        \n",
    "        Args:\n",
    "            algo (str): The algorithm of object detection tasks. \"resnet\"(default), \"yolov3\", \"yolo_tiny\".\n",
    "            speed (str): The detection speed for object detetion tasks. \"normal\"(default), \"fast\", \"faster\" , \"fastest\" and \"flash\".\n",
    "        \n",
    "        Returns:\n",
    "            void\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        if algo == \"resnet\":\n",
    "            self.detector.setModelTypeAsRetinaNet()\n",
    "            self.detector.setModelPath(\n",
    "                os.path.join(self.target_img_path, self.algos[\"resnet\"]))\n",
    "        elif algo == \"yolov3\":\n",
    "            self.detector.setModelTypeAsYOLOv3()\n",
    "            self.detector.setModelPath(\n",
    "                os.path.join(self.target_img_path, self.algos[\"yolov3\"]))\n",
    "        elif algo == \"yolo_tiny\":\n",
    "            self.detector.setModelTypeAsTinyYOLOv3()\n",
    "            self.detector.setModelPath(\n",
    "                os.path.join(self.target_img_path, self.algos[\"yolo_tiny\"]))\n",
    "        else:\n",
    "            print(\"Given algorithm of object detection is invalid.\")\n",
    "            return\n",
    "\n",
    "        self.detector.loadModel(detection_speed=speed)\n",
    "        self.custom_objects = self.detector.CustomObjects(person=True)\n",
    "\n",
    "    def put_text_to_img(self, img, text, pos = (50,50), fontColor=(0,0,255), lineType=2):\n",
    "        \"\"\"\n",
    "        Put text to an image.\n",
    "        \n",
    "        Args:\n",
    "            img : An image represented by numpy array. You can use cv2.imread(path_to_iamge) to read an image in the filesystem by\n",
    "                    giving the image path.\n",
    "            text (str): The text what you want to put to the image.\n",
    "            pos (tuple): x and y position relative to the origin (0,0) at the top left.\n",
    "            fontColor (tuple): R G B channel.\n",
    "            lineType (int): Type of line.\n",
    "        \n",
    "        Returns:\n",
    "            void\n",
    "        \n",
    "        \"\"\"\n",
    "        if img is None:\n",
    "            print(\"Put text to a none image.\")\n",
    "            return\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 1\n",
    "\n",
    "        cv2.putText(img, text, pos, font, fontScale, fontColor, lineType)\n",
    "\n",
    "    def capture_frame_by_stream_wrapper(self,\n",
    "                                        image_prefix=\"stream\",\n",
    "                                        mprob=30,\n",
    "                                        num_im=6,\n",
    "                                        time_interval=10,\n",
    "                                        tz=None):\n",
    "        \"\"\"\n",
    "        A wrapper of the function capture_frame_by_stream.\n",
    "        \n",
    "        Args:\n",
    "            image_prefix (str): Prefix of target images. The postfix is numerated by numbers.\n",
    "            mprob (int): Minimum probability to be a person.\n",
    "            num_im (int): How many images will be taken.\n",
    "            time_interval (int): Time interval of taking next image, the unit is second.\n",
    "\t\t\ttz (str): Time zone from package pytz. Default is None, then apply utc time. Use function pytz.all_timezones to get the list of timezones.\n",
    "        \n",
    "        Returns:\n",
    "            void\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"The current conuting function is based on capture frame by stream.\")\n",
    "\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        frames_res = []\n",
    "        if num_im <= 0:\n",
    "            try:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    i = i + 1\n",
    "                    frame_res = self.capture_frame_by_stream(\n",
    "                        image_prefix, i, mprob, tz)\n",
    "                    frames.res.append(frame_res)\n",
    "                    time.sleep(time_interval)\n",
    "            except KeyboardInterrupt:\n",
    "                return frames_res\n",
    "                print('Abort by key interrupt.')\n",
    "        else:\n",
    "            for i in range(num_im):\n",
    "                frame_res = self.capture_frame_by_stream(\n",
    "                    image_prefix, i, mprob, tz)\n",
    "                frames_res.append(frame_res)\n",
    "                time.sleep(time_interval)\n",
    "\n",
    "            return frames_res\n",
    "\n",
    "    def capture_frame_by_stream(self,\n",
    "                                image_prefix=\"stream\",\n",
    "                                image_index=0,\n",
    "                                mprob=30,\n",
    "                                tz=None) -> int:\n",
    "        \"\"\"\n",
    "        capture a frame from a online stream, namely webcam.\n",
    "        \n",
    "        Args:\n",
    "            image_prefix (str): Prefix of target images. The postfix is numerated by numbers.\n",
    "            image_index (int): The postfix of target images. By default, numerated from 0.\n",
    "            mprob (int): Minimum probability to be a person.\n",
    "\t\t    tz (str): Time zone from package pytz. Default is None, then apply utc time. Use function pytz.all_timezones to get the list of timezones.\n",
    "\n",
    "\t\t\n",
    "        Returns:\n",
    "            tuple: The name of target image, the number of persons in an image detected by the model and the current time.\n",
    "        \"\"\"\n",
    "\t\t\n",
    "        video_cap = cv2.VideoCapture(self.stream.url)\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "\n",
    "        if video_cap is None:\n",
    "            print(\"Open webcam [%s] failed.\" % self.stream.url)\n",
    "            return None\n",
    "        else:\n",
    "            ret, frame = video_cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Captured frame is broken.\")\n",
    "                video_cap.release()\n",
    "                return None\n",
    "            else:\n",
    "                print(\"-----------------------------------------------------\")\n",
    "                \n",
    "\n",
    "                if tz is None:\n",
    "                    current_time = datetime.utcnow().strftime(\n",
    "                        \"%a %Y-%m-%d %H:%M:%S\")\n",
    "                    print('### time zone is None, therefore use utc time###')\n",
    "                else:\n",
    "                    current_time = datetime.now(\n",
    "                        timezone(tz)).strftime(\"%a %Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                print(\"Capturing frame %d.\" % image_index)\n",
    "                target_img_name = \"{}{}.png\".format(image_prefix, image_index)\n",
    "                # frame = crop_frame(frame, target_img_name)  # comment to unuse the crop function.\n",
    "                \n",
    "                cv2.imwrite(os.path.join(dir_path, target_img_name), frame)\n",
    "\n",
    "                detections = self.detector.detectCustomObjectsFromImage(\n",
    "                    custom_objects=self.custom_objects,\n",
    "                    input_image=os.path.join(dir_path, target_img_name),\n",
    "                    output_image_path=os.path.join(dir_path, target_img_name),\n",
    "                    minimum_percentage_probability=mprob)\n",
    "\n",
    "                print(\n",
    "                    \"The number of person in frame %d (%s):\" %\n",
    "                    (image_index, target_img_name), len(detections))\n",
    "                print(\n",
    "                    \"The current time in frame %d (%s):\" %\n",
    "                    (image_index, target_img_name), current_time)\n",
    "\n",
    "                img = cv2.imread(os.path.join(dir_path, target_img_name))\n",
    "                # put the number of persons to the image and put timestamp to the image\n",
    "                self.put_text_to_img(\n",
    "                    img, \"The number of person:%s \" % str(len(detections)))\n",
    "                img_height, img_width = img.shape[0:2]\n",
    "                self.put_text_to_img(\n",
    "                    img, \"The current time:%s \" % current_time, pos=(int(img_width*0.1), int(img_height*0.9)))\n",
    "\n",
    "                cv2.imwrite(os.path.join(dir_path, target_img_name), img)\n",
    "                video_cap.release()\n",
    "\n",
    "                return target_img_name, len(detections), current_time\n",
    "\n",
    "    def capture_frame_by_screenshot_wrapper(self,\n",
    "                                            image_prefix=\"screenshot\",\n",
    "                                            mprob=30,\n",
    "                                            num_im=6,\n",
    "                                            time_interval=10,\n",
    "                                            tz=None):\n",
    "        \"\"\"\n",
    "        A wrapper of the function capture_frame_by_screenshot.\n",
    "        \n",
    "        Args:\n",
    "            image_prefix (str): Prefix of target images. The postfix is numerated by numbers.\n",
    "            mprob (int): Minimum probability to be a person.\n",
    "            num_im (int): How many images will be taken.\n",
    "            time_interval (int): Time interval of taking next image, the unit is second.\n",
    "\t\t\ttz (str): Time zone from package pytz. Default is None, then apply utc time. Use function pytz.all_timezones to get the list of timezones.\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "            void\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\n",
    "            \"The current conuting function is based on capture frame by screenshot.\"\n",
    "        )\n",
    "\n",
    "        frames_res = []\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        if num_im <= 0:\n",
    "            try:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    i = i + 1\n",
    "                    frame_res = self.capture_frame_by_screenshot(\n",
    "                        image_prefix, i, mprob, tz)\n",
    "                    frames_res.append(frame_res)\n",
    "                    time.sleep(time_interval)\n",
    "            except KeyboardInterrupt:\n",
    "                if self.driver is not None:\n",
    "                    self.driver.quit()\n",
    "                return frames_res\n",
    "                print('Abort by key interrupt.')\n",
    "        else:\n",
    "            for i in range(num_im):\n",
    "                frame_res = self.capture_frame_by_screenshot(\n",
    "                    image_prefix, i, mprob, tz)\n",
    "                frames_res.append(frame_res)\n",
    "                time.sleep(time_interval)\n",
    "\n",
    "            if self.driver is not None:\n",
    "                self.driver.quit()\n",
    "\n",
    "            return frames_res\n",
    "\n",
    "    def capture_frame_by_screenshot(self,\n",
    "                                    image_prefix=\"screenshot\",\n",
    "                                    image_index=0,\n",
    "                                    mprob=30,\n",
    "                                    num_im=6,\n",
    "                                    tz=None) -> int:\n",
    "        \"\"\"\n",
    "       capture an image by taking a screenshot on an opened website via browser.\n",
    "        \n",
    "        Args:\n",
    "            image_prefix (str): Prefix of target images. The postfix is numerated by numbers.\n",
    "            image_index (int): The postfix of target images. By default, numerated from 0.\n",
    "            mprob (int): Minimum probability to be a person.\n",
    "\t\t\ttz (str): Time zone from package pytz. Default is None, then apply utc time. Use function pytz.all_timezones to get the list of timezones.\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "            tuple: The name of target image, the number of persons in an image detected by the model and the current time.\n",
    "        \n",
    "        \"\"\"\n",
    "\t\t\n",
    "        dir_path = os.path.join(self.target_img_path, image_prefix)\n",
    "\n",
    "        if self.driver is None:\n",
    "            print(\"Web driver is none.\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"-----------------------------------------------------\")\n",
    "\n",
    "            if tz is None:\n",
    "                current_time = datetime.utcnow().strftime(\n",
    "                    \"%a %Y-%m-%d %H:%M:%S\")\n",
    "                print('### time zone is None, therefore use utc time###')\n",
    "            else:\n",
    "                current_time = datetime.now(\n",
    "                    timezone(tz)).strftime(\"%a %Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            target_img_name = \"{}{}.png\".format(image_prefix, image_index)\n",
    "            print(\"Taking screenshot %d...\" % image_index)\n",
    "            self.driver.save_screenshot(\n",
    "                os.path.join(dir_path, target_img_name))\n",
    "            detections = self.detector.detectCustomObjectsFromImage(\n",
    "                custom_objects=self.custom_objects,\n",
    "                input_image=os.path.join(dir_path,\n",
    "                                         target_img_name),\n",
    "                output_image_path=os.path.join(dir_path, target_img_name),\n",
    "                minimum_percentage_probability=mprob)\n",
    "\n",
    "            print(\n",
    "                \"The number of person in frame %d (%s):\" % (image_index,\n",
    "                                                            target_img_name),\n",
    "                len(detections))\n",
    "            print(\n",
    "                \"The current time in frame %d (%s):\" %\n",
    "                (image_index, target_img_name), current_time)\n",
    "\n",
    "            img = cv2.imread(os.path.join(dir_path, target_img_name))\n",
    "            # put the number of persons to the image\n",
    "            self.put_text_to_img(\n",
    "                img, \"The number of person is:%s\" % str(len(detections)))\n",
    "            img_height, img_width = img.shape[0:2]\n",
    "            self.put_text_to_img(\n",
    "                img, \"The current time:%s \" % current_time, pos=(int(img_width*0.1), int(img_height*0.9)))\n",
    "\n",
    "            cv2.imwrite(os.path.join(dir_path, target_img_name), img)\n",
    "\n",
    "            return target_img_name, len(detections), current_time\n",
    "\n",
    "    def init_webdriver(self):\n",
    "        \"\"\"\n",
    "       Initialize the webdriver of Chrome by using the python lib selenium.\n",
    "        \n",
    "        Args:\n",
    "            Void\n",
    "        \n",
    "        Returns:\n",
    "            Void\n",
    "        \"\"\"\n",
    "\t\t\n",
    "        self.driver = webdriver.Chrome(\n",
    "        )  # Optional argument, if not specified will search path.\n",
    "        self.driver.get(self.stream_link)\n",
    "        time.sleep(15)  # Jump over the ads\n",
    "        \n",
    "    def stroe_info_in_df_csv(self, image_prefix=\"counting_person\"):\n",
    "        \"\"\"\n",
    "       Collect test dataset by storing the image name and the detected number of persons in a csv file.\n",
    "        \n",
    "        Args:\n",
    "            info():  \n",
    "        \n",
    "        Returns:\n",
    "            Void\n",
    "        \"\"\"\n",
    "\t\t\n",
    "        df = pd.DataFrame(\n",
    "            np.array(res), columns=['image_name', 'detected_num', 'time'])\n",
    "        # df[\"counted_num\"] = \"\"  #only for baseline\n",
    "        df.to_csv(\n",
    "            path_or_buf=os.path.join(self.target_img_path, \"%s.csv\" %\n",
    "                                     image_prefix))\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "def crop_frame(frame, target_img_name, y1=150, y2=500, x1=0, x2=1000):\n",
    "    \"\"\"\n",
    "    only crop frame to evaluate the baseline. not a offical function, therefore outsied the class. will be deleted after evaluation.\n",
    "    \"\"\"\n",
    "    frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "    if not os.path.isdir('.\\\\dublin_day_baseline'):\n",
    "        os.makedirs('.\\\\dublin_day_baseline')\n",
    "    path = '.\\\\dublin_day_baseline'\n",
    "    cv2.imwrite(os.path.join(path, target_img_name), frame)\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Starting...\")\n",
    "    counting_person = CountingObject(dublin)\n",
    "    counting_person.detector_init()\n",
    "\n",
    "    by_stream_flag = False\n",
    "    img_prefix = \"dublin_day\"\n",
    "    res = []\n",
    "    if by_stream_flag:\n",
    "        res = counting_person.capture_frame_by_stream_wrapper(\n",
    "            image_prefix=img_prefix, num_im=2, time_interval=5, tz=Dublin)\n",
    "\n",
    "    else:\n",
    "        counting_person.init_webdriver()\n",
    "        res = counting_person.capture_frame_by_screenshot_wrapper(num_im=2)\n",
    "\n",
    "#     counting_person.store_baseline_info_in_csv(res)\n",
    "    df = counting_person.stroe_info_in_df_csv(image_prefix=img_prefix)\n",
    "    display(df)\n",
    "\n",
    "    print('###Exit...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
