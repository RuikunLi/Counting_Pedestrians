{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T20:37:13.008550Z",
     "start_time": "2018-12-12T20:34:57.387325Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "The current conuting function is based on capture frame by stream.\n",
      "-----------------------------------------------------\n",
      "Capturing frame 0.\n",
      "The number of person in frame 0 (dublin0.png): 6\n",
      "The current time in frame 0 (dublin0.png): Wed Dec 12 21:36:43 2018\n",
      "-----------------------------------------------------\n",
      "Capturing frame 1.\n",
      "The number of person in frame 1 (dublin1.png): 10\n",
      "The current time in frame 1 (dublin1.png): Wed Dec 12 21:37:02 2018\n",
      "###Exit...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlink\n",
    "from imageai.Detection import VideoObjectDetection, ObjectDetection\n",
    "# from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "\n",
    "def crop_frame(frame, target_img_name,y1=150,y2=500,x1=0,x2=1000):\n",
    "    \"\"\"\n",
    "    only crop frame to evaluate the baseline. not a offical function, therefore outsied the class. will be deleted after evaluation.\n",
    "    \"\"\"\n",
    "    frame = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    if not os.path.isdir('.\\\\baseline'):\n",
    "        os.makedirs('.\\\\baseline')\n",
    "    path = '.\\\\baseline'\n",
    "    cv2.imwrite(os.path.join(path , target_img_name), frame)\n",
    "    return frame\n",
    "\n",
    "\n",
    "london = 'https://www.earthcam.com/world/england/london/abbeyroad/?cam=abbeyroad_uk'\n",
    "timesquare = 'https://www.earthcam.com/usa/newyork/timessquare/?cam=tsrobo1'\n",
    "dublin = 'https://www.earthcam.com/world/ireland/dublin/?cam=templebar'\n",
    "\n",
    "class CountingObject(object):\n",
    "    \"\"\"\n",
    "    A class of counting objects\n",
    "    \"\"\"\n",
    "    \n",
    "    algos = {\"resnet\": \"resnet50_coco_best_v2.0.1.h5\", \"yolov3\": \"yolo.h5\", \"yolo_tiny\": \"yolo-tiny.h5\"}\n",
    "    \n",
    "    def __init__(self, stream_link):\n",
    "        self.stream_link = stream_link\n",
    "        self.streams = streamlink.streams(stream_link)\n",
    "        if self.streams is None:\n",
    "            raise ValueError(\"cannot open the stream link %s\" % stream_link)\n",
    "        \n",
    "        #change 1, self detect quality\n",
    "        q = list(self.streams.keys())[0]\n",
    "        self.stream = self.streams['%s'%q]\n",
    "        \n",
    "        self.target_img_path = os.getcwd()\n",
    "        \n",
    "        self.detector = ObjectDetection()\n",
    "        if self.detector is None:\n",
    "            raise ValueError(\"Detector of objects is None\")\n",
    "        \n",
    "        \n",
    "    def detector_init(self, algo=\"resnet\", speed=\"nomal\"):\n",
    "        \"\"\"\n",
    "        Must be invoked after instantiate for initialize a object detector. \n",
    "        \n",
    "        Args:\n",
    "            algo (str): The algorithm of object detection tasks. \"resnet\"(default), \"yolov3\", \"yolo_tiny\".\n",
    "            speed (str): The detection speed for object detetion tasks. \"normal\"(default), \"fast\", \"faster\" , \"fastest\" and \"flash\".\n",
    "        \n",
    "        Returns:\n",
    "            void\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if algo == \"resnet\":\n",
    "            self.detector.setModelTypeAsRetinaNet()\n",
    "            self.detector.setModelPath(os.path.join(self.target_img_path, self.algos[\"resnet\"]))\n",
    "        elif algo == \"yolov3\":\n",
    "            self.detector.setModelTypeAsYOLOv3()\n",
    "            self.detector.setModelPath(os.path.join(self.target_img_path, self.algos[\"yolov3\"]))\n",
    "        elif algo == \"yolo_tiny\":\n",
    "            self.detector.setModelTypeAsTinyYOLOv3()\n",
    "            self.detector.setModelPath(os.path.join(self.target_img_path, self.algos[\"yolo_tiny\"])) \n",
    "        else:\n",
    "            print(\"Given algorithm of object detection is invalid.\")\n",
    "            return\n",
    "        \n",
    "        self.detector.loadModel(detection_speed=speed)\n",
    "        self.custom_objects = self.detector.CustomObjects(person=True)\n",
    "\n",
    "    def put_text_to_img(self, img, text, pos=(50,50), fontColor=(0,0,255), lineType=2):\n",
    "        if img is None:\n",
    "            print(\"Put text to a none image.\")\n",
    "            return\n",
    "        \n",
    "        font                  = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale             = 1\n",
    "\n",
    "        cv2.putText(img, text,  \n",
    "                    pos, \n",
    "                    font, \n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "        \n",
    "    def capture_frame_by_stream_wrapper(self, image_prefix=\"stream\", mprob=30, num_im=6, time_interval=10):\n",
    "        print(\"The current conuting function is based on capture frame by stream.\")\n",
    "        dir_path = '%s\\%s'%(self.target_img_path,image_prefix)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        frames_res = []\n",
    "        if num_im <= 0:\n",
    "            try:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    i = i + 1\n",
    "                    frame_res = self.capture_frame_by_stream(image_prefix, i, mprob)\n",
    "                    frames.res.append(frame_res)\n",
    "                    time.sleep(time_interval)\n",
    "            except KeyboardInterrupt:\n",
    "                return frames_res\n",
    "                print('Abort by key interrupt.')\n",
    "        else:\n",
    "            for i in range(num_im):\n",
    "                frame_res = self.capture_frame_by_stream(image_prefix, i, mprob)\n",
    "                frames_res.append(frame_res)\n",
    "                time.sleep(time_interval)\n",
    "            \n",
    "            return frames_res\n",
    "        \n",
    "        \n",
    "\n",
    "    def capture_frame_by_stream(self, image_prefix=\"stream\", image_index=0, mprob=30)->int:\n",
    "        video_cap = cv2.VideoCapture(self.stream.url)\n",
    "        dir_path = os.path.join(self.target_img_path,image_prefix)\n",
    "        if video_cap is None:\n",
    "            print(\"Open webcam [%s] failed.\" % self.stream.url)\n",
    "            return None\n",
    "        else:\n",
    "            ret, frame = video_cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                print(\"Captured frame is broken.\")\n",
    "                video_cap.release()\n",
    "                return None\n",
    "            else:\n",
    "                print(\"-----------------------------------------------------\")\n",
    "                \n",
    "                print(\"Capturing frame %d.\" % image_index)\n",
    "                target_img_name = \"{}{}.png\".format(image_prefix, image_index)\n",
    "                frame = crop_frame(frame,target_img_name)# comment to unuse the crop function.\n",
    "\n",
    "                detections = self.detector.detectCustomObjectsFromImage(custom_objects=self.custom_objects, \n",
    "                      input_type=\"array\", \n",
    "                      input_image=frame, \n",
    "                      output_image_path=os.path.join(dir_path , target_img_name), \n",
    "                      minimum_percentage_probability=mprob)\n",
    "\n",
    "                print(\"The number of person in frame %d (%s):\" % (image_index, target_img_name), len(detections))\n",
    "                print(\"The current time in frame %d (%s):\" % (image_index, target_img_name), time.asctime())\n",
    "\n",
    "\n",
    "                img = cv2.imread(os.path.join(dir_path , target_img_name))\n",
    "                # put the number of persons to the image and put timestamp to the image\n",
    "                self.put_text_to_img(img, \"The number of person:%s \" % str(len(detections)))\n",
    "                self.put_text_to_img(img, \"The current time:%s \" % time.asctime(), pos=(50,300))\n",
    "\n",
    "#               cv2.imshow(\"image\", img)\n",
    "                cv2.imwrite(os.path.join(dir_path , target_img_name), img)\n",
    "#               cv2.waitKey(0) # blocked until pressing Enter key\n",
    "#               cv2.destroyAllWindows()\n",
    "                video_cap.release()\n",
    "            \n",
    "                return {'img_name':target_img_name, 'detected_num':len(detections)}\n",
    "        \n",
    "    def capture_frame_by_screenshot_wrapper(self, image_prefix=\"screenshot\", mprob=30, num_im=6, time_interval=10):\n",
    "        print(\"The current conuting function is based on capture frame by screenshot.\")\n",
    "        \n",
    "        frames_res = []\n",
    "        dir_path = os.path.join(self.target_img_path,image_prefix)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        if num_im <= 0:\n",
    "            try:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    i = i + 1\n",
    "                    frame_res = self.capture_frame_by_screenshot(image_prefix, i, mprob)\n",
    "                    frames_res.append(frame_res)\n",
    "                    time.sleep(time_interval)\n",
    "            except KeyboardInterrupt:\n",
    "                if self.driver is not None:\n",
    "                    self.driver.quit()\n",
    "                return frames_res\n",
    "                print('Abort by key interrupt.')\n",
    "        else:\n",
    "            for i in range(num_im):\n",
    "                frame_res = self.capture_frame_by_screenshot(image_prefix, i, mprob)\n",
    "                frames_res.append(frame_res)\n",
    "                time.sleep(time_interval)\n",
    "                \n",
    "            if self.driver is not None:\n",
    "                self.driver.quit()\n",
    "            \n",
    "            return frames_res\n",
    "                \n",
    "    def capture_frame_by_screenshot(self, image_prefix=\"screenshot\", image_index=0, mprob=30, num_im=6)->int:\n",
    "                \n",
    "        if self.driver is None:\n",
    "            print(\"Web driver is none.\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"-----------------------------------------------------\")\n",
    "            target_img_name = \"{}{}.png\".format(image_prefix, image_index)\n",
    "            print(\"Taking screenshot %d...\" % image_index)\n",
    "            print(\"image path:%s\" % os.path.join(self.target_img_path, target_img_name))\n",
    "            self.driver.save_screenshot(os.path.join(self.target_img_path, target_img_name))\n",
    "            detections = self.detector.detectCustomObjectsFromImage(custom_objects=self.custom_objects, \n",
    "                                              input_image=os.path.join(self.target_img_path, target_img_name), \n",
    "                                              output_image_path=os.path.join(dir_path, target_img_name), \n",
    "                                              minimum_percentage_probability=mprob)\n",
    "\n",
    "            print(\"The number of person in frame %d (%s):\" % (image_index, target_img_name), len(detections))\n",
    "            print(\"The current time in frame %d (%s):\" % (image_index, target_img_name), time.asctime())\n",
    "\n",
    "            img = cv2.imread(os.path.join(dir_path, target_img_name))\n",
    "            # put the number of persons to the image\n",
    "            self.put_text_to_img(img, \"The number of person is:%s\" % str(len(detections)))\n",
    "            self.put_text_to_img(img, \"The current time:%s \" % time.asctime(),pos=(50,300))\n",
    "\n",
    "            cv2.imwrite(os.path.join(dir_path , target_img_name), img)\n",
    "        \n",
    "            return {'img_name':target_img_name, 'detected_num':len(detections)}\n",
    "\n",
    "    def init_webdriver(self):\n",
    "        self.driver = webdriver.Chrome()  # Optional argument, if not specified will search path.\n",
    "        self.driver.get(self.stream_link)\n",
    "        time.sleep(15) # Jump over the ads\n",
    "        \n",
    "    def store_baseline_info_in_csv(self, info):\n",
    "        if info is None:\n",
    "            print(\"Given baseline data is None.\")\n",
    "            return\n",
    "        baseline_info_path = os.path.join(self.target_img_path, \"baseline.csv\")\n",
    "       \n",
    "        with open(baseline_info_path, \"w+\") as csv_file:\n",
    "            field_names = [\"img_name\", \"countable_num\", \"detected_num\"]\n",
    "            csv_writer = csv.DictWriter(csv_file, fieldnames= field_names, restval=0)\n",
    "            csv_writer.writeheader()\n",
    "            for item in info:\n",
    "                csv_writer.writerow(item)\n",
    "                \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "#     scheduler = BlockingScheduler()\n",
    "    print(\"Starting...\")\n",
    "    counting_person = CountingObject(dublin)\n",
    "    counting_person.detector_init()\n",
    "\n",
    "    by_stream_flag = True\n",
    "    res = []\n",
    "    if by_stream_flag:\n",
    "        res = counting_person.capture_frame_by_stream_wrapper(image_prefix=\"dublin\",num_im=2)\n",
    "    else:\n",
    "        counting_person.init_webdriver()\n",
    "        res = counting_person.capture_frame_by_screenshot_wrapper(num_im=2)\n",
    "    counting_person.store_baseline_info_in_csv(res)\n",
    "    \n",
    "    print('###Exit...')\n",
    "        \n",
    "#  raises errors, nor ready for using.\n",
    "#     scheduler.add_job(capture_frame, 'interval', seconds=5, args=[cap, detect, custom_objects, target_img_path])\n",
    "#     scheduler.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
