{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "london = 'https://www.earthcam.com/world/england/london/abbeyroad/?cam=abbeyroad_uk'\n",
    "timesquare = 'https://www.earthcam.com/usa/newyork/timessquare/?cam=tsrobo1'\n",
    "dublin = 'https://www.earthcam.com/world/ireland/dublin/?cam=templebar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "The current algorithm is resnet. \n",
      "The current speed is nomal. \n",
      "The current conuting function is based on capture frame by stream.\n",
      "-----------------------------------------------------\n",
      "Capturing frame 0.\n",
      "The number of person in frame 0 (stream_0_result.png ): 17\n",
      "The current time in frame 0 (stream_0_result.png ): Fri Nov 30 20:14:02 2018\n",
      "-----------------------------------------------------\n",
      "Capturing frame 1.\n",
      "The number of person in frame 1 (stream_1_result.png ): 15\n",
      "The current time in frame 1 (stream_1_result.png ): Fri Nov 30 20:14:22 2018\n",
      "[17, 15]\n",
      "###exit.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import streamlink\n",
    "from imageai.Detection import VideoObjectDetection, ObjectDetection\n",
    "# from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "class CountingObject(object):\n",
    "    \"\"\"\n",
    "    A class of counting objects\n",
    "    \"\"\"\n",
    "    \n",
    "    algos = {\"resnet\": \"resnet50_coco_best_v2.0.1.h5\", \"yolov3\": \"yolo.h5\", \"yolo_tiny\": \"yolo-tiny.h5\"}\n",
    "    \n",
    "    def __init__(self, stream_link):\n",
    "        self.stream_link = stream_link\n",
    "        self.streams = streamlink.streams(stream_link)\n",
    "        if self.streams is None:\n",
    "            raise ValueError(\"cannot open the stream link %s\" % stream_link)\n",
    "        \n",
    "        #change 1, self detect quality\n",
    "        q = list(self.streams.keys())[0]\n",
    "        self.stream = self.streams['%s'%q]\n",
    "        \n",
    "        self.target_img_path = os.getcwd()\n",
    "        \n",
    "        self.detector = ObjectDetection()\n",
    "        if self.detector is None:\n",
    "            raise ValueError(\"Detector of objects is None\")\n",
    "        \n",
    "        \n",
    "    def detector_init(self, algo=\"resnet\", speed=\"nomal\"):\n",
    "        \"\"\"\n",
    "        Must be invoked after instantiate for initialize a object detector. \n",
    "        \n",
    "        Args:\n",
    "            algo (str): The algorithm of object detection tasks. \"resnet\"(default), \"yolov3\", \"yolo_tiny\".\n",
    "            speed (str): The detection speed for object detetion tasks. \"normal\"(default), \"fast\", \"faster\" , \"fastest\" and \"flash\".\n",
    "        \n",
    "        Returns:\n",
    "            void\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"The current algorithm is %s. \"%algo)\n",
    "        print(\"The current speed is %s. \"%speed)\n",
    "        if algo == \"resnet\":\n",
    "            self.detector.setModelTypeAsRetinaNet()\n",
    "            self.detector.setModelPath(os.path.join(self.target_img_path, self.algos[\"resnet\"]))\n",
    "           \n",
    "        elif algo == \"yolov3\":\n",
    "            self.detector.setModelTypeAsYOLOv3()\n",
    "            self.detector.setModelPath(os.path.join(self.target_img_path, self.algos[\"yolov3\"]))\n",
    "            \n",
    "        elif algo == \"yolo_tiny\":\n",
    "            self.detector.setModelTypeAsTinyYOLOv3()\n",
    "            self.detector.setModelPath(os.path.join(self.target_img_path, self.algos[\"yolo_tiny\"]))\n",
    "           \n",
    "        else:\n",
    "            print(\"Given algorithm of object detection is invalid.\")\n",
    "            return\n",
    "        \n",
    "        self.detector.loadModel(detection_speed=speed)\n",
    "        self.custom_objects = self.detector.CustomObjects(person=True)\n",
    "\n",
    "    def put_text_to_img(self, img, text,pos = (50,50),fontColor=(0,0,255),lineType=2):\n",
    "        if img is None:\n",
    "            print(\"Put text to a none image.\")\n",
    "            return\n",
    "        \n",
    "        font                  = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale             = 1\n",
    "\n",
    "        cv2.putText(img, text,  \n",
    "                    pos, \n",
    "                    font, \n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "    #change 2 add nim,tin\n",
    "    def capture_frame_by_stream(self,imagename=\"stream\",mpp=30,num_im=6,time_interval=10):\n",
    "        print(\"The current conuting function is based on capture frame by stream.\")\n",
    "        number_list = []\n",
    "              \n",
    "        for i in range(num_im):\n",
    "        \n",
    "            video_cap = cv2.VideoCapture(self.stream.url)\n",
    "            if video_cap is None:\n",
    "                print(\"Open webcam [%s] failed.\" % self.stream.url)\n",
    "                return\n",
    "            else:\n",
    "                ret, frame = video_cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    print(\"Captured frame is broken.\")\n",
    "                    return \n",
    "                else:\n",
    "                    print(\"-----------------------------------------------------\")\n",
    "                    print(\"Capturing frame %d.\"%i)\n",
    "                    detections = self.detector.detectCustomObjectsFromImage(custom_objects=self.custom_objects, \n",
    "                          input_type=\"array\", \n",
    "                          input_image=frame, \n",
    "                          output_image_path=os.path.join(self.target_img_path , \"%s_%d_result.png\" %(imagename,i)), \n",
    "                          minimum_percentage_probability=mpp)\n",
    "                    \n",
    "                    print(\"The number of person in frame %d (%s_%d_result.png ):\"%(i,imagename,i), len(detections))\n",
    "                    print(\"The current time in frame %d (%s_%d_result.png ):\"%(i,imagename,i), time.asctime())\n",
    "                   \n",
    "                    \n",
    "                    img = cv2.imread(os.path.join(self.target_img_path, \"%s_%d_result.png\" %(imagename,i)))\n",
    "                    # put the number of persons to the image and put timestamp to the image\n",
    "                    self.put_text_to_img(img, \"The number of person:%s \"%str(len(detections)))\n",
    "                    self.put_text_to_img(img, \"The current time:%s \"%time.asctime(),pos=(50,450),fontColor=())\n",
    "                    \n",
    "#                     cv2.imshow(\"image\", img)\n",
    "                    cv2.imwrite(\"%s_%d_result.png\" %(imagename,i),img)\n",
    "#                     cv2.waitKey(0) # blocked until pressing Enter key\n",
    "#                     cv2.destroyAllWindows()\n",
    "                    number_list.append(len(detections))                   \n",
    "            video_cap.release()\n",
    "            time.sleep(time_interval)\n",
    "        print(number_list)\n",
    "        return number_list\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "    def capture_frame_by_screenshot(self,imagename=\"screenshot\",mpp=30,num_im=6,time_interval=10):\n",
    "        print(\"The current conuting function is based on capture frame by screenshot.\")\n",
    "        number_list = []\n",
    "        \n",
    "        \n",
    "        if self.driver is None:\n",
    "            print(\"Web driver is none.\")\n",
    "            return \n",
    "        else:\n",
    "            \n",
    "            for i in range(num_im):\n",
    "                print(\"-----------------------------------------------------\")\n",
    "                print('Taking screenshot %d...'%i)\n",
    "                self.driver.save_screenshot(\"%s_%d.png\" %(imagename,i))\n",
    "                detections = self.detector.detectCustomObjectsFromImage(custom_objects=self.custom_objects, \n",
    "                                                  input_image=os.path.join(self.target_img_path , \"%s_%d.png\" %(imagename,i)), \n",
    "                                                  output_image_path=os.path.join(self.target_img_path , \"%s_%d.png\" %(imagename,i)), \n",
    "                                                  minimum_percentage_probability=mpp)\n",
    "                \n",
    "                print(\"The number of person in frame %d (%s_%d_result.png ):\"%(i,imagename,i), len(detections))\n",
    "                print(\"The current time in frame %d (%s_%d_result.png ):\"%(i,imagename,i), time.asctime())\n",
    "                \n",
    "                img = cv2.imread(os.path.join(self.target_img_path, \"%s_%d.png\" %(imagename,i)))\n",
    "                # put the number of persons to the image\n",
    "                self.put_text_to_img(img, \"The number of person is:%s\"%str(len(detections)))\n",
    "                self.put_text_to_img(img, \"The current time:%s \"%time.asctime(),pos=(50,450),fontColor=())\n",
    "\n",
    "               \n",
    "                cv2.imwrite(\"%s_%d_result.png\" %(imagename,i),img)\n",
    "                time.sleep(time_interval)\n",
    "                number_list.append(len(detections)) \n",
    "        \n",
    "        self.driver.quit()\n",
    "        print(number_list)\n",
    "        return number_list\n",
    "\n",
    "    def init_webdriver(self):\n",
    "        self.driver = webdriver.Chrome(os.path.join('E:/Googledriver/chromedriver_win32/chromedriver.exe'))  # Optional argument, if not specified will search path.\n",
    "        self.driver.get(self.stream_link)\n",
    "        time.sleep(15) # Jump over the ads\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "#     scheduler = BlockingScheduler()\n",
    "    print(\"Starting...\")\n",
    "    counting_person = CountingObject(dublin)\n",
    "    counting_person.detector_init()\n",
    "\n",
    "    dublin = counting_person.capture_frame_by_stream(num_im=2)\n",
    "\n",
    "#     counting_person.init_webdriver()\n",
    "#     counting_person.capture_frame_by_screenshot(num_im=2)\n",
    "\n",
    "        \n",
    "    print('###exit.')\n",
    "        \n",
    "#  raises errors, nor ready for using.\n",
    "#     scheduler.add_job(capture_frame, 'interval', seconds=5, args=[cap, detect, custom_objects, target_img_path])\n",
    "#     scheduler.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean(dublin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dublin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
